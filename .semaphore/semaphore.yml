version: v1.0
name: build-test-release
agent:
  machine:
    type: s1-prod-ubuntu24-04-amd64-1
execution_time_limit:
  hours: 3
global_job_config:
  env_vars:
    - name: LIBRDKAFKA_VERSION
      value: v2.12.0
  prologue:
    commands:
      - checkout
      - mkdir artifacts
blocks:
  - name: "Wheels: OSX x64 - Python 3.8-3.12"
    # run:
    #   when: "tag =~ '.*'"
    dependencies: []
    task:
      agent:
        machine:
          type: s1-macos-15-amd64-6
      env_vars:
        - name: OS_NAME
          value: osx
        - name: ARCH
          value: x64
      jobs:
        - name: Build
          commands:
            - sem-version python 3.11
            - PIP_INSTALL_OPTIONS="--user" tools/wheels/build-wheels.sh "${LIBRDKAFKA_VERSION#v}" wheelhouse 2.16.2
            - tar -czf wheelhouse-macOS-${ARCH}.tgz wheelhouse
            - artifact push workflow wheelhouse-macOS-${ARCH}.tgz --destination artifacts/wheels-${OS_NAME}-${ARCH}.tgz/
  - name: "Wheels: OSX x64 - Python 3.13-3.14"
    # run:
    #   when: "tag =~ '.*'"
    dependencies: []
    task:
      agent:
        machine:
          type: s1-macos-15-amd64-6
      env_vars:
        - name: OS_NAME
          value: osx
        - name: ARCH
          value: x64
        - name: CIBW_SKIP
          value: cp36-* cp37-* cp38-* cp39-* cp310-* cp311-* cp312-*
        - name: CIBW_ENVIRONMENT_MACOS
          value: MACOSX_DEPLOYMENT_TARGET=15
      jobs:
        - name: Build
          commands:
            - sem-version python 3.13
            - PIP_INSTALL_OPTIONS="--user" tools/wheels/build-wheels.sh "${LIBRDKAFKA_VERSION#v}" wheelhouse
            - tar -czf wheelhouse-macOS-${ARCH}-py313-plus.tgz wheelhouse
            - artifact push workflow wheelhouse-macOS-${ARCH}-py313-plus.tgz --destination artifacts/wheels-${OS_NAME}-${ARCH}-py313-plus.tgz/
  - name: "Wheels: OSX arm64 - Python 3.8-3.12"
    # run:
    #   when: "tag =~ '.*'"
    dependencies: []
    task:
      agent:
        machine:
          type: s1-macos-15-arm64-8
      env_vars:
        - name: OS_NAME
          value: osx
        - name: CIBW_ARCHS
          value: arm64
        - name: ARCH
          value: arm64
      jobs:
        - name: Build
          commands:
            - sem-version python 3.11
            - PIP_INSTALL_OPTIONS="--user" tools/wheels/build-wheels.sh "${LIBRDKAFKA_VERSION#v}" wheelhouse 2.16.2
            - tar -czf wheelhouse-macOS-${ARCH}.tgz wheelhouse
            - artifact push workflow wheelhouse-macOS-${ARCH}.tgz --destination artifacts/wheels-${OS_NAME}-${ARCH}.tgz/
  - name: "Wheels: OSX arm64 - Python 3.13-3.14"
    # run:
    #   when: "tag =~ '.*'"
    dependencies: []
    task:
      agent:
        machine:
          type: s1-macos-15-arm64-8
      env_vars:
        - name: OS_NAME
          value: osx
        - name: CIBW_ARCHS
          value: arm64
        - name: ARCH
          value: arm64
        - name: CIBW_SKIP
          value: cp38-* cp39-* cp310-* cp311-* cp312-*
        - name: CIBW_ENVIRONMENT_MACOS
          value: MACOSX_DEPLOYMENT_TARGET=15
      jobs:
        - name: Build
          commands:
            - sem-version python 3.13
            - PIP_INSTALL_OPTIONS="--user" tools/wheels/build-wheels.sh "${LIBRDKAFKA_VERSION#v}" wheelhouse
            - tar -czf wheelhouse-macOS-${ARCH}-py313-plus.tgz wheelhouse
            - artifact push workflow wheelhouse-macOS-${ARCH}-py313-plus.tgz --destination artifacts/wheels-${OS_NAME}-${ARCH}-py313-plus.tgz/
  - name: "Wheels: Linux arm64"
    # run:
    #   when: "tag =~ '.*'"
    dependencies: []
    task:
      agent:
        machine:
          type: s1-prod-ubuntu24-04-arm64-1
      env_vars:
        - name: OS_NAME
          value: linux
        - name: ARCH
          value: arm64
      jobs:
        - name: Build
          commands:
            - sem-version python 3.13
            - ./tools/wheels/build-wheels.sh "${LIBRDKAFKA_VERSION#v}" wheelhouse
            - tar -czf wheelhouse-linux-${ARCH}.tgz wheelhouse
            - artifact push workflow wheelhouse-linux-${ARCH}.tgz --destination artifacts/wheels-${OS_NAME}-${ARCH}.tgz/
  - name: "Wheels: Linux x64"
    # run:
    #   when: "tag =~ '.*'"
    dependencies: []
    task:
      agent:
        machine:
          type: s1-prod-ubuntu24-04-amd64-3
      env_vars:
        - name: OS_NAME
          value: linux
        - name: ARCH
          value: x64
      jobs:
        - name: Build
          commands:
            - sem-version python 3.11
            - ./tools/wheels/build-wheels.sh "${LIBRDKAFKA_VERSION#v}" wheelhouse
            - tar -czf wheelhouse-linux-${ARCH}.tgz wheelhouse
            - artifact push workflow wheelhouse-linux-${ARCH}.tgz --destination artifacts/wheels-${OS_NAME}-${ARCH}.tgz/
  - name: "Wheels: Windows"
    # run:
    #   when: "tag =~ '.*'"
    dependencies: []
    task:
      agent:
          machine:
            type: s1-prod-windows
      env_vars:
        - name: OS_NAME
          value: windows
        - name: ARCH
          value: x64
      prologue:
        commands:
          - ".\\tools\\mingw-w64\\setup-msys2.ps1"
          - $env:PATH = 'C:\msys64\usr\bin;' + $env:PATH
          - bash -lc './tools/mingw-w64/msys2-dependencies.sh'
      jobs:
        - name: Build
          env_vars:
            - name: CHERE_INVOKING
              value: 'yes'
            - name: MSYSTEM
              value: UCRT64
          commands:
            - pyenv install 3.11
            - pyenv global 3.11
            - bash tools/mingw-w64/semaphore_commands.sh
            - bash tools/wheels/install-librdkafka.sh $env:LIBRDKAFKA_VERSION.TrimStart("v") dest
            - tools/wheels/build-wheels.bat x64 win_amd64 dest wheelhouse
            - tar -czf wheelhouse-windows-${Env:ARCH}.tgz wheelhouse
            - artifact push workflow wheelhouse-windows-${Env:ARCH}.tgz --destination artifacts/wheels-${Env:OS_NAME}-${Env:ARCH}.tgz/
  - name: "Source package verification and Integration tests with Python 3 (Linux x64)"
    dependencies: []
    task:
      agent:
        machine:
          type: s1-prod-ubuntu24-04-amd64-3
      env_vars:
        - name: OS_NAME
          value: linux
        - name: ARCH
          value: x64
      prologue:
        commands:
          - '[[ -z $DOCKERHUB_APIKEY ]] || docker login --username $DOCKERHUB_USER --password $DOCKERHUB_APIKEY'
      jobs:
        - name: Build and Tests with 'classic' group protocol
          commands:
            - sem-version python 3.9
            # use a virtualenv
            - python3 -m venv _venv && source _venv/bin/activate
            - chmod u+r+x tools/source-package-verification.sh
            - tools/source-package-verification.sh
        - name: Build and Tests with 'consumer' group protocol
          commands:
            - sem-version python 3.9
            - sem-version java 17
            # use a virtualenv
            - python3 -m venv _venv && source _venv/bin/activate
            - chmod u+r+x tools/source-package-verification.sh
            - export TEST_CONSUMER_GROUP_PROTOCOL=consumer
            - tools/source-package-verification.sh
        - name: Build, Test, and Report coverage
          commands:
            - sem-version python 3.9
            # use a virtualenv
            - python3 -m venv _venv && source _venv/bin/activate
            - chmod u+r+x tools/source-package-verification.sh
            - export RUN_COVERAGE=true
            - tools/source-package-verification.sh
            - mkdir test-output
            - cp test-report.xml test-output
            - test-results publish test-output
            - artifact push workflow coverage.xml
  - name: "Source package verification with Python 3 (Linux arm64)"
    dependencies: []
    task:
      agent:
        machine:
          type: s1-prod-ubuntu24-04-arm64-1
      env_vars:
        - name: OS_NAME
          value: linux
        - name: ARCH
          value: arm64
      jobs:
        - name: Build
          commands:
            - sem-version python 3.9
            # use a virtualenv
            - python3 -m venv _venv && source _venv/bin/activate
            - chmod u+r+x tools/source-package-verification.sh
            - tools/source-package-verification.sh
  - name: "Source package verification with Python 3 (OSX x64) +docs"
    dependencies: []
    task:
      agent:
        machine:
          type: s1-macos-15-amd64-6
      env_vars:
        - name: OS_NAME
          value: osx
        - name: ARCH
          value: x64
      jobs:
        - name: Build
          commands:
            - sem-version python 3.9
            # use a virtualenv
            - python3 -m venv _venv && source _venv/bin/activate
            - chmod u+r+x tools/source-package-verification.sh
            - tools/source-package-verification.sh
  - name: "Source package verification with Python 3 (OSX arm64) +docs"
    dependencies: []
    task:
      agent:
        machine:
          type: s1-macos-15-arm64-8
      env_vars:
        - name: OS_NAME
          value: osx
        - name: ARCH
          value: arm64
      jobs:
        - name: Build
          commands:
            - sem-version python 3.9
            # use a virtualenv
            - python3 -m venv _venv && source _venv/bin/activate
            - chmod u+r+x tools/source-package-verification.sh
            - tools/source-package-verification.sh
  - name: "Ducktape Performance Tests (Linux x64)"
    dependencies: []
    task:
      agent:
        machine:
          type: s1-prod-ubuntu24-04-amd64-3
      env_vars:
        - name: OS_NAME
          value: linux
        - name: ARCH
          value: x64
        - name: BENCHMARK_BOUNDS_CONFIG
          value: tests/ducktape/producer_benchmark_bounds.json
        - name: BENCHMARK_ENVIRONMENT
          value: ci
      prologue:
        commands:
          - '[[ -z $DOCKERHUB_APIKEY ]] || docker login --username $DOCKERHUB_USER --password $DOCKERHUB_APIKEY'
      jobs:
        - name: Build and Tests
          commands:
            # Setup Python environment
            - sem-version python 3.9
            - python3 -m venv _venv && source _venv/bin/activate

            # Install ducktape framework and additional dependencies
            - pip install ducktape psutil

            # Install existing test requirements
            - pip install -r requirements/requirements-tests-install.txt

            # Build and install confluent-kafka from source
            - lib_dir=dest/runtimes/$OS_NAME-$ARCH/native
            - tools/wheels/install-librdkafka.sh "${LIBRDKAFKA_VERSION#v}" dest
            - export CFLAGS="$CFLAGS -I${PWD}/dest/build/native/include"
            - export LDFLAGS="$LDFLAGS -L${PWD}/${lib_dir}"
            - export LD_LIBRARY_PATH="$LD_LIBRARY_PATH:$PWD/$lib_dir"
            - python3 -m pip install -e .

            # Store project root for reliable navigation
            - PROJECT_ROOT="${PWD}"

            # Start Kafka cluster and Schema Registry using dedicated ducktape compose file (KRaft mode)
            - cd "${PROJECT_ROOT}/tests/docker"
            - docker-compose -f docker-compose.ducktape.yml up -d kafka schema-registry

            # Debug: Check container status and logs
            - echo "=== Container Status ==="
            - docker-compose -f docker-compose.ducktape.yml ps
            - echo "=== Kafka Logs ==="
            - docker-compose -f docker-compose.ducktape.yml logs kafka | tail -50

            # Wait for Kafka to be ready (using PLAINTEXT listener for external access)
            - |
              timeout 1800 bash -c '
                counter=0
                until docker-compose -f docker-compose.ducktape.yml exec -T kafka kafka-topics --bootstrap-server localhost:9092 --list >/dev/null 2>&1; do
                  echo "Waiting for Kafka... (attempt $((counter+1)))"

                  # Show logs every 4th attempt (every 20 seconds)
                  if [ $((counter % 4)) -eq 0 ] && [ $counter -gt 0 ]; then
                    echo "=== Recent Kafka Logs ==="
                    docker-compose -f docker-compose.ducktape.yml logs --tail=10 kafka
                    echo "=== Container Status ==="
                    docker-compose -f docker-compose.ducktape.yml ps kafka
                  fi

                  counter=$((counter+1))
                  sleep 5
                done
              '
            - echo "Kafka cluster is ready!"

            # Wait for Schema Registry to be ready
            - echo "=== Waiting for Schema Registry ==="
            - |
              timeout 300 bash -c '
                counter=0
                until curl -f http://localhost:8081/subjects >/dev/null 2>&1; do
                  echo "Waiting for Schema Registry... (attempt $((counter+1)))"

                  # Show logs every 3rd attempt (every 15 seconds)
                  if [ $((counter % 3)) -eq 0 ] && [ $counter -gt 0 ]; then
                    echo "=== Recent Schema Registry Logs ==="
                    docker-compose -f docker-compose.ducktape.yml logs --tail=10 schema-registry
                    echo "=== Schema Registry Container Status ==="
                    docker-compose -f docker-compose.ducktape.yml ps schema-registry
                  fi

                  counter=$((counter+1))
                  sleep 5
                done
              '
            - echo "Schema Registry is ready!"

            # Run standard ducktape tests with CI bounds
            - cd "${PROJECT_ROOT}" && PYTHONPATH="${PROJECT_ROOT}" python tests/ducktape/run_ducktape_test.py

            # Cleanup
            - cd "${PROJECT_ROOT}/tests/docker" && docker-compose -f docker-compose.ducktape.yml down -v || true
  - name: "Packaging"
    # run:
    #   when: "tag =~ '.*'"
    dependencies:
      - "Wheels: OSX x64 - Python 3.8-3.12"
      - "Wheels: OSX x64 - Python 3.13-3.14"
      - "Wheels: OSX arm64 - Python 3.8-3.12"
      - "Wheels: OSX arm64 - Python 3.13-3.14"
      - "Wheels: Linux arm64"
      - "Wheels: Linux x64"
      - "Wheels: Windows"
    task:
      agent:
        machine:
          type: s1-prod-ubuntu24-04-amd64-3
      jobs:
        - name: "Packaging all artifacts"
          commands:
            - artifact pull workflow artifacts
            - cd artifacts
            - ls *.tgz |xargs -n1 tar -xvf
            - tar cvf confluent-kafka-python-wheels-${SEMAPHORE_GIT_TAG_NAME}-${SEMAPHORE_WORKFLOW_ID}.tgz wheelhouse/
            - ls -la
            - sha256sum confluent-kafka-python-wheels-${SEMAPHORE_GIT_TAG_NAME}-${SEMAPHORE_WORKFLOW_ID}.tgz
            - cd ..
            - artifact push project artifacts/confluent-kafka-python-wheels-${SEMAPHORE_GIT_TAG_NAME}-${SEMAPHORE_WORKFLOW_ID}.tgz --destination confluent-kafka-python-wheels-${SEMAPHORE_GIT_TAG_NAME}-${SEMAPHORE_WORKFLOW_ID}.tgz
            - echo Thank you

after_pipeline:
  task:
    agent:
      machine:
        type: s1-prod-ubuntu24-04-amd64-1
    jobs:
      - name: SonarQube
        commands:
          - checkout
          - sem-version java 11
          - artifact pull workflow coverage.xml
          - emit-sonarqube-data --run_only_sonar_scan
